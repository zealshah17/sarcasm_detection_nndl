{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SetFit MODEL - 3** \n",
    "\n",
    "**Model: MiniLM-L3-v2**\n",
    "\n",
    "N = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/xd91rcv91cq23cjjl0_c93nh0000gn/T/ipykernel_82227/1468048697.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
      "`SentenceTransformer._target_device` has been deprecated, please use `SentenceTransformer.device` instead.\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to training dataset\n",
      "Generating Training Pairs: 100%|██████████| 50/50 [00:00<00:00, 2996.53it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 3200\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 200\n",
      "  Total train batch size = 16\n",
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6480 | F1 Score: 0.6576\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_PATH = \"multilang_sarcasm_dataset.csv\"\n",
    "MODEL_PATH = \"model/setfit_multilang_sarcasm_en\"\n",
    "N_SHOT = 16\n",
    "MAX_TEST_SAMPLES = 1000\n",
    "\n",
    "# === LOAD & PREPROCESS ===\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Filter to English headlines\n",
    "df = df[df[\"lang\"] == \"en\"]\n",
    "\n",
    "# Rename columns to match SETFIT input format\n",
    "df = df[[\"article_title\", \"is_sarcastic\"]].rename(columns={\"article_title\": \"text\", \"is_sarcastic\": \"label\"})\n",
    "\n",
    "# Drop any potential NaNs\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "# === TRAIN/TEST SPLIT ===\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Few-shot sampling\n",
    "def sample_few_shot(df, n=64):\n",
    "    return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "fewshot_train_df = sample_few_shot(train_df, N_SHOT)\n",
    "test_subset_df = test_df.sample(n=min(len(test_df), MAX_TEST_SAMPLES), random_state=42)\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(fewshot_train_df)\n",
    "test_dataset = Dataset.from_pandas(test_subset_df)\n",
    "\n",
    "# === LOAD BASE MODEL ===\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "# === TRAIN SETUP ===\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=50,\n",
    "    num_epochs=1,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "\n",
    "# Evaluate\n",
    "y_true = test_dataset[\"label\"]\n",
    "y_pred = model.predict(test_dataset[\"text\"])\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SetFit MODEL - 3** \n",
    "\n",
    "**Model: MiniLM-L3-v2**\n",
    "\n",
    "N = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lv/xd91rcv91cq23cjjl0_c93nh0000gn/T/ipykernel_82227/292298277.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
      "`SentenceTransformer._target_device` has been deprecated, please use `SentenceTransformer.device` instead.\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to training dataset\n",
      "Generating Training Pairs: 100%|██████████| 50/50 [00:00<00:00, 1391.36it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 6400\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 400\n",
      "  Total train batch size = 16\n",
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6900 | F1 Score: 0.6645\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_PATH = \"multilang_sarcasm_dataset.csv\"\n",
    "MODEL_PATH = \"model/setfit_multilang_sarcasm_en_32\"\n",
    "N_SHOT = 32\n",
    "MAX_TEST_SAMPLES = 1000\n",
    "\n",
    "# === LOAD & PREPROCESS ===\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Filter to English headlines\n",
    "df = df[df[\"lang\"] == \"en\"]\n",
    "\n",
    "# Rename columns to match SETFIT input format\n",
    "df = df[[\"article_title\", \"is_sarcastic\"]].rename(columns={\"article_title\": \"text\", \"is_sarcastic\": \"label\"})\n",
    "\n",
    "# Drop any potential NaNs\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "# === TRAIN/TEST SPLIT ===\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Few-shot sampling\n",
    "def sample_few_shot(df, n=64):\n",
    "    return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "fewshot_train_df = sample_few_shot(train_df, N_SHOT)\n",
    "test_subset_df = test_df.sample(n=min(len(test_df), MAX_TEST_SAMPLES), random_state=42)\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(fewshot_train_df)\n",
    "test_dataset = Dataset.from_pandas(test_subset_df)\n",
    "\n",
    "# === LOAD BASE MODEL ===\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "# === TRAIN SETUP ===\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=50,\n",
    "    num_epochs=1,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "\n",
    "# Evaluate\n",
    "y_true = test_dataset[\"label\"]\n",
    "y_pred = model.predict(test_dataset[\"text\"])\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SetFit MODEL - 3** \n",
    "\n",
    "**Model: MiniLM-L3-v2**\n",
    "\n",
    "N = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/lv/xd91rcv91cq23cjjl0_c93nh0000gn/T/ipykernel_82829/450116200.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
      "`SentenceTransformer._target_device` has been deprecated, please use `SentenceTransformer.device` instead.\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Applying column mapping to training dataset\n",
      "Generating Training Pairs: 100%|██████████| 50/50 [00:00<00:00, 1095.85it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 12800\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 800\n",
      "  Total train batch size = 16\n",
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 00:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.166300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7150 | F1 Score: 0.7016\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_PATH = \"multilang_sarcasm_dataset.csv\"\n",
    "MODEL_PATH = \"model/setfit_multilang_sarcasm_en_64\"\n",
    "N_SHOT = 64\n",
    "MAX_TEST_SAMPLES = 1000\n",
    "\n",
    "# === LOAD & PREPROCESS ===\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Filter to English headlines\n",
    "df = df[df[\"lang\"] == \"en\"]\n",
    "\n",
    "# Rename columns to match SETFIT input format\n",
    "df = df[[\"article_title\", \"is_sarcastic\"]].rename(columns={\"article_title\": \"text\", \"is_sarcastic\": \"label\"})\n",
    "\n",
    "# Drop any potential NaNs\n",
    "df = df.dropna(subset=[\"text\", \"label\"])\n",
    "\n",
    "# === TRAIN/TEST SPLIT ===\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "# Few-shot sampling\n",
    "def sample_few_shot(df, n=64):\n",
    "    return df.groupby(\"label\").apply(lambda x: x.sample(n=min(n, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "fewshot_train_df = sample_few_shot(train_df, N_SHOT)\n",
    "test_subset_df = test_df.sample(n=min(len(test_df), MAX_TEST_SAMPLES), random_state=42)\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(fewshot_train_df)\n",
    "test_dataset = Dataset.from_pandas(test_subset_df)\n",
    "\n",
    "# === LOAD BASE MODEL ===\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "# === TRAIN SETUP ===\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=50,\n",
    "    num_epochs=1,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "\n",
    "# Evaluate\n",
    "y_true = test_dataset[\"label\"]\n",
    "y_pred = model.predict(test_dataset[\"text\"])\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} | F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
